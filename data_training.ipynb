{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import cntk as C\n",
    "import cntk.tests.test_utils\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)\n",
    "C.cntk_py.set_fixed_random_seed(1) # fix the random seed so that LR examples are repeatable\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "num_output_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "\n",
    "    labelStream = C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False)\n",
    "    featureStream = C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)\n",
    "\n",
    "    deserailizer = C.io.CTFDeserializer(path, C.io.StreamDefs(labels = labelStream, features = featureStream))\n",
    "\n",
    "    return C.io.MinibatchSource(deserailizer,\n",
    "       randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is DataSets\\MNIST\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(\"DataSets\", \"MNIST\")\n",
    "\n",
    "train_file = os.path.join(data_dir, \"Train-28x28_cntk_text.txt\")\n",
    "test_file = os.path.join(data_dir, \"Test-28x28_cntk_text.txt\")\n",
    "\n",
    "print(\"Data directory is {0}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = C.input_variable(input_dim)\n",
    "label = C.input_variable(num_output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(features, no_of_hidden_neurons = 1024):\n",
    "    with C.layers.default_options(init = C.glorot_uniform()):\n",
    "        r = C.layers.Dense(no_of_hidden_neurons, activation = None)(features)\n",
    "        r = C.layers.Dense(num_output_classes, activation = None)(r)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_train = create_reader(train_file, True, input_dim, num_output_classes)\n",
    "\n",
    "# Map the data streams to the input and labels.\n",
    "input_map = {\n",
    "    label  : reader_train.streams.labels,\n",
    "    input  : reader_train.streams.features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, learning_rate = 0.1, momentum = 0.9, max_epochs = 50, dataset_multiplier = 1):\n",
    "\n",
    "    minibatch_size = 64\n",
    "    num_samples_per_sweep = 60000\n",
    "    num_sweeps_to_train_with = 10\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / minibatch_size\n",
    "\n",
    "    loss = C.cross_entropy_with_softmax(model, label)\n",
    "    label_error = C.classification_error(model, label)\n",
    "\n",
    "    # Run the trainer on and perform model training\n",
    "    training_progress_output_freq = 500\n",
    "\n",
    "    # Training Parameters\n",
    "    progress_printer = C.logging.ProgressPrinter(tag='Training', num_epochs=max_epochs)\n",
    "    lr_schedule = C.learning_parameter_schedule(learning_rate)\n",
    "    momentums = C.momentum_schedule(momentum, minibatch_size = minibatch_size)\n",
    "\n",
    "    learner = C.momentum_sgd(model.parameters, lr_schedule, momentum = momentums)\n",
    "    trainer = C.Trainer(model, (loss, label_error), [learner], [progress_printer])\n",
    "\n",
    "    \n",
    "    plotdata = {\"epoch\":[], \"loss\":[], \"error\":[]}\n",
    "    progress_printer = C.logging.ProgressPrinter(tag='Training', num_epochs=max_epochs)\n",
    "\n",
    "    batch_index = 0\n",
    "    for epoch in range(max_epochs):       # loop over epochs\n",
    "        avg_loss = 0\n",
    "        avg_error = 0\n",
    "        for i in range(0, int(num_minibatches_to_train * dataset_multiplier)):\n",
    "\n",
    "            # Read a mini batch from the training data file\n",
    "            data = reader_train.next_minibatch(minibatch_size, input_map = input_map)\n",
    "            trainer.train_minibatch(data)\n",
    "            \n",
    "            avg_loss += trainer.previous_minibatch_loss_average\n",
    "            avg_error += trainer.previous_minibatch_evaluation_average\n",
    "\n",
    "        plotdata[\"epoch\"].append(epoch)\n",
    "        plotdata[\"loss\"].append(avg_loss / int(num_minibatches_to_train))\n",
    "        plotdata[\"error\"].append(avg_error / int(num_minibatches_to_train))\n",
    "        trainer.summarize_training_progress()\n",
    "    return plotdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(plotdata = {}):\n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    plt.plot(plotdata[\"epoch\"], plotdata[\"loss\"], 'b--')\n",
    "    plt.xlabel('Epoch number')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Epoch run vs. Training loss')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(plotdata[\"epoch\"], plotdata[\"error\"], 'r--')\n",
    "    plt.xlabel('Epoch number')\n",
    "    plt.ylabel('Label Prediction Error')\n",
    "    plt.title('Epoch run vs. Label Prediction Error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expreiment 1\n",
    "\n",
    "## Vary number of hidden units\n",
    "\n",
    "### n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z1_1 = create_model(input/255.0, no_of_hidden_neurons=20)\n",
    "\n",
    "data1_1 = train_network(z1_1)\n",
    "\n",
    "plot_data(data1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1_2 = create_model(input/255.0, no_of_hidden_neurons=50)\n",
    "\n",
    "data1_2 = train_network(z1_2)\n",
    "\n",
    "plot_data(data1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1_3 = create_model(input/255.0, no_of_hidden_neurons=100)\n",
    "\n",
    "data1_3 = train_network(z1_3)\n",
    "\n",
    "plot_data(data1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expreiment 2\n",
    "\n",
    "## Vary Momentums\n",
    "\n",
    "### momentum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = create_model(input/255.0, no_of_hidden_neurons=100)\n",
    "\n",
    "data2_1 = train_network(z2, momentum = 0, max_epochs = 20)\n",
    "\n",
    "plot_data(data2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### momentum = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2_2 = create_model(input/255.0, no_of_hidden_neurons=100)\n",
    "\n",
    "data2_2 = train_network(z2_2, momentum = 0.25, max_epochs = 20)\n",
    "\n",
    "plot_data(data2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### momentum = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2_3 = create_model(input/255.0, no_of_hidden_neurons=100)\n",
    "\n",
    "data2_3 = train_network(z2_3, momentum = 0.5, max_epochs = 20)\n",
    "\n",
    "plot_data(data2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expreiment 3\n",
    "\n",
    "## Vary Dataset Size\n",
    "\n",
    "### dataset_size = 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
